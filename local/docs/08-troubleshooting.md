# üö® Troubleshooting Guide - Nexo CloudLab

Guia de solu√ß√£o de problemas comuns no CloudLab.

## Script Autom√°tico

```bash
# Rodar diagn√≥stico completo
./scripts/troubleshoot.sh

# Ou via Make
make troubleshoot
```

## Problemas Comuns

### 1. Cluster n√£o inicia

#### Sintoma

```bash
k3d cluster create --config config/k3d-config.yaml
# Error: ...
```

#### Solu√ß√µes

**Docker n√£o est√° rodando**

```bash
# Verificar
docker info

# Solu√ß√£o
open -a Docker
# Aguardar Docker iniciar
```

**Porta j√° em uso**

```bash
# Ver o que est√° usando as portas
lsof -i :80
lsof -i :443

# Matar processo
kill -9 <PID>

# Ou usar portas diferentes em k3d-config.yaml
```

**SSD n√£o montado**

```bash
# Verificar
ls -la /Volumes/Backup

# Se n√£o existir, montar o disco ou criar diret√≥rio local
mkdir -p ~/nexo-cloudlab-storage
# Editar config/k3d-config.yaml para usar ~/nexo-cloudlab-storage
```

### 2. Pods em CrashLoopBackOff

#### Sintoma

```bash
kubectl get pods -A
# NAME              STATUS             RESTARTS
# my-pod-xxx        CrashLoopBackOff   5
```

#### Debug

```bash
# Ver logs atuais
kubectl logs <pod> -n <namespace>

# Ver logs do container anterior
kubectl logs <pod> -n <namespace> --previous

# Describe para ver eventos
kubectl describe pod <pod> -n <namespace>

# Ver eventos do namespace
kubectl get events -n <namespace> --sort-by='.lastTimestamp'
```

#### Causas Comuns

**Image Pull Error**

```bash
# Sintoma: ImagePullBackOff

# Verificar
kubectl describe pod <pod> -n <namespace> | grep -A 5 "Events:"

# Solu√ß√µes:
# 1. Verificar se imagem existe
docker pull <image>

# 2. Verificar imagePullSecrets
kubectl get deployment <name> -n <namespace> -o yaml | grep imagePullSecrets

# 3. Criar secret se necess√°rio
kubectl create secret docker-registry ghcr-secret \
  --docker-server=ghcr.io \
  --docker-username=<user> \
  --docker-password=<token> \
  -n <namespace>
```

**Falta de Recursos**

```bash
# Sintoma: Insufficient memory/cpu

# Ver recursos dispon√≠veis
kubectl describe node | grep -A 5 "Allocated resources"

# Solu√ß√µes:
# 1. Reduzir resources do pod
# 2. Aumentar recursos do Docker Desktop (Settings ‚Üí Resources)
# 3. Deletar pods n√£o usados
kubectl delete pod <pod> -n <namespace>
```

**ConfigMap/Secret n√£o existe**

```bash
# Sintoma: Error: couldn't find key X in ConfigMap

# Verificar
kubectl get configmap -n <namespace>
kubectl get secret -n <namespace>

# Criar se necess√°rio
kubectl create configmap <name> --from-literal=key=value -n <namespace>
kubectl create secret generic <name> --from-literal=key=value -n <namespace>
```

### 3. Ingress n√£o funciona

#### Sintoma

```bash
curl http://nexo-be.local.nexo.dev
# Connection refused / 404
```

#### Debug

```bash
# Verificar Ingress Controller
kubectl get pods -n ingress-nginx

# Ver logs
kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller

# Ver ingresses
kubectl get ingress -A

# Describe ingress
kubectl describe ingress <name> -n <namespace>
```

#### Solu√ß√µes

**Ingress Controller n√£o est√° rodando**

```bash
helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace
```

**DNS n√£o configurado**

```bash
# Verificar /etc/hosts
cat /etc/hosts | grep local.nexo.dev

# Adicionar se n√£o existir
echo "127.0.0.1 nexo-be.local.nexo.dev" | sudo tee -a /etc/hosts
```

**Service n√£o existe**

```bash
# Ver services
kubectl get svc -n <namespace>

# Se n√£o existir, verificar deployment
kubectl get deployment -n <namespace>
```

### 4. ArgoCD n√£o sincroniza

#### Sintoma

```bash
argocd app get myapp
# Status: OutOfSync
# Sync: Failed
```

#### Debug

```bash
# Ver detalhes do erro
argocd app get myapp

# Ver logs do sync
argocd app logs myapp

# Ver diff
argocd app diff myapp

# Ver eventos
kubectl get events -n argocd --sort-by='.lastTimestamp'
```

#### Solu√ß√µes

**Erro de sintaxe no YAML**

```bash
# Validar manifesto localmente
helm template ./chart --debug

# Ou
kubectl apply --dry-run=client -f manifest.yaml
```

**Repo n√£o acess√≠vel**

```bash
# Verificar repo
argocd repo list

# Adicionar credenciais se necess√°rio
argocd repo add https://github.com/user/repo \
  --username <user> \
  --password <token>
```

**Path n√£o existe**

```bash
# Verificar path no repo
git clone <repo>
ls -la <path>

# Corrigir Application
kubectl edit application myapp -n argocd
```

### 5. Prometheus sem m√©tricas

#### Sintoma

```
Grafana: No data
Prometheus: Target down
```

#### Debug

```bash
# Ver targets
kubectl port-forward -n monitoring svc/prometheus-operated 9090:9090
# Acessar: http://localhost:9090/targets

# Ver ServiceMonitors
kubectl get servicemonitor -n monitoring

# Ver logs do Prometheus
kubectl logs -n monitoring prometheus-kube-prometheus-stack-prometheus-0
```

#### Solu√ß√µes

**ServiceMonitor n√£o tem label correto**

```yaml
# ServiceMonitor precisa ter:
metadata:
  labels:
    release: kube-prometheus-stack
```

**Service n√£o exp√µe /metrics**

```bash
# Testar diretamente
kubectl port-forward -n <namespace> svc/<service> 8080:8080
curl http://localhost:8080/metrics
```

**Namespace n√£o est√° sendo monitorado**

```yaml
# Verificar namespaceSelector no ServiceMonitor
spec:
  namespaceSelector:
    matchNames:
      - <namespace>
```

### 6. Elasticsearch Yellow/Red

#### Sintoma

```bash
curl http://localhost:9200/_cluster/health
# "status": "yellow" ou "red"
```

#### Debug

```bash
# Ver estado do cluster
curl http://localhost:9200/_cluster/health?pretty

# Ver shards
curl http://localhost:9200/_cat/shards?v

# Ver aloca√ß√£o
curl http://localhost:9200/_cat/allocation?v
```

#### Solu√ß√µes

**Replicas n√£o podem alocar (single node)**

```bash
# Reduzir replicas para 0
curl -X PUT "localhost:9200/_settings?pretty" -H 'Content-Type: application/json' -d'
{
  "index": {
    "number_of_replicas": 0
  }
}
'
```

**Disco cheio**

```bash
# Ver uso de disco
kubectl exec -n logging elasticsearch-master-0 -- df -h

# Deletar √≠ndices antigos
curl -X DELETE "localhost:9200/filebeat-$(date -d '7 days ago' +%Y.%m.%d)?pretty"
```

**Shards n√£o realocam**

```bash
# For√ßar realoca√ß√£o
curl -X POST "localhost:9200/_cluster/reroute?retry_failed=true&pretty"
```

### 7. Pods Pending

#### Sintoma

```bash
kubectl get pods
# NAME         STATUS    RESTARTS
# my-pod-xxx   Pending   0
```

#### Debug

```bash
kubectl describe pod <pod> -n <namespace>
# Ver se√ß√£o "Events:"
```

#### Causas

**Insufficient CPU/Memory**

```bash
# Ver recursos dispon√≠veis
kubectl top nodes

# Solu√ß√µes:
# 1. Deletar pods n√£o usados
# 2. Reduzir resources.requests
# 3. Aumentar recursos do cluster
```

**Volume n√£o pode ser montado**

```bash
# Ver PVC
kubectl get pvc -n <namespace>

# Se Pending, verificar StorageClass
kubectl get storageclass

# Ver events do PVC
kubectl describe pvc <pvc-name> -n <namespace>
```

**Node selector n√£o matched**

```bash
# Ver node labels
kubectl get nodes --show-labels

# Remover nodeSelector ou adicionar label ao node
kubectl label node <node> <key>=<value>
```

### 8. Out of Memory

#### Sintoma

```bash
kubectl get pods
# NAME         STATUS    RESTARTS
# my-pod-xxx   OOMKilled 5
```

#### Solu√ß√µes

```yaml
# Aumentar memory limit
resources:
  limits:
    memory: 1Gi # Era 512Mi
  requests:
    memory: 512Mi
```

```bash
# Ver uso de mem√≥ria
kubectl top pods -n <namespace>

# Ver hist√≥rico no Grafana
# Dashboard ‚Üí Kubernetes Pods ‚Üí Memory Usage
```

### 9. Network Policies bloqueando

#### Sintoma

```
Pods n√£o conseguem comunicar
Timeout ao chamar services
```

#### Debug

```bash
# Ver network policies
kubectl get networkpolicies -A

# Describe
kubectl describe networkpolicy <name> -n <namespace>

# Testar conectividade
kubectl run -it --rm debug --image=nicolaka/netshoot --restart=Never -- bash
# Dentro do pod:
curl http://service-name.namespace:port
```

#### Solu√ß√£o

```bash
# Deletar policy temporariamente
kubectl delete networkpolicy <name> -n <namespace>

# Ou corrigir policy para permitir tr√°fego
```

### 10. Certificate/TLS Issues

#### Sintoma

```
x509: certificate signed by unknown authority
```

#### Para ambiente local

```yaml
# Desabilitar TLS verificatio em ingress
ingress:
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
```

## Comandos de Emerg√™ncia

### Restart Everything

```bash
# Restart todos pods de um namespace
kubectl delete pods --all -n <namespace>

# Restart deployment
kubectl rollout restart deployment <name> -n <namespace>

# Restart daemonset
kubectl rollout restart daemonset <name> -n <namespace>
```

### Force Delete

```bash
# Deletar pod travado
kubectl delete pod <pod> -n <namespace> --force --grace-period=0

# Remover finalizers
kubectl patch pod <pod> -n <namespace> -p '{"metadata":{"finalizers":[]}}' --type=merge
```

### Clean Cluster

```bash
# Deletar pods failed/completed
kubectl delete pods --field-selector=status.phase=Failed -A
kubectl delete pods --field-selector=status.phase=Succeeded -A

# Limpar Docker
docker system prune -a
```

### Nuclear Option

```bash
# Deletar tudo e recome√ßar
make clean
make install
```

## Logs Importantes

### Cluster

```bash
# Kubernetes events
kubectl get events -A --sort-by='.lastTimestamp' | tail -n 50

# Node logs (via Docker)
docker logs k3d-nexo-local-server-0
docker logs k3d-nexo-local-agent-0
```

### Componentes

```bash
# ArgoCD
kubectl logs -n argocd -l app.kubernetes.io/name=argocd-server

# Prometheus
kubectl logs -n monitoring prometheus-kube-prometheus-stack-prometheus-0

# Grafana
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana

# Elasticsearch
kubectl logs -n logging elasticsearch-master-0

# Ingress
kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller
```

## üóëÔ∏è Quando Reinstalar do Zero

√Äs vezes, a solu√ß√£o mais r√°pida √© destruir tudo e reinstalar. Use o comando **destroy** quando:

- Muitas coisas quebradas ao mesmo tempo
- Configura√ß√µes corrompidas
- Problemas persistentes sem causa clara
- Quer come√ßar limpo ap√≥s testes

### Op√ß√µes de Limpeza

#### 1. Delete (apenas cluster)

Remove apenas o cluster, mant√©m volumes:

```bash
make delete
# ou
k3d cluster delete nexo-local
```

**Use quando:** Quer recriar o cluster mas manter dados (Prometheus, ES, etc)

#### 2. Clean (cluster + volumes)

Remove cluster e limpa volumes do SSD:

```bash
make clean
```

**Use quando:** Quer limpar dados mas manter /etc/hosts

#### 3. Destroy (TUDO)

Remove TUDO de forma interativa com confirma√ß√£o:

```bash
make destroy
# ou
cd local && ./destroy.sh
```

**Remove:**

- ‚úÖ Todos os Helm releases (ArgoCD, Prometheus, ES, etc)
- ‚úÖ Todos os namespaces
- ‚úÖ Cluster k3d completo
- ‚úÖ Volumes persistentes (com confirma√ß√£o)
- ‚úÖ Entradas no /etc/hosts (com confirma√ß√£o)

**Use quando:**

- Problemas graves sem solu√ß√£o clara
- Quer come√ßar 100% do zero
- Vai recriar o ambiente completo

### Processo Completo de Reinstala√ß√£o

```bash
# 1. Destroy completo
cd local
make destroy
# Confirme as op√ß√µes interativas (volumes e /etc/hosts)

# 2. Reinstalar
make setup

# 3. Verificar
make status
make urls
```

### Backup Antes de Destroy

**SEMPRE fa√ßa backup antes de destruir:**

```bash
# Backup completo
make backup

# Backup manual de recursos importantes
kubectl get all -A -o yaml > backup-all-resources.yaml
kubectl get configmaps -A -o yaml > backup-configmaps.yaml
kubectl get secrets -A -o yaml > backup-secrets.yaml
```

Os backups ficam em: `/Volumes/Backup/nexo-cloudlab/backups/`

## Quando Pedir Ajuda

Se nada funcionar, colete informa√ß√µes e pe√ßa ajuda:

```bash
# Gerar relat√≥rio completo
./scripts/troubleshoot.sh > troubleshoot-report.txt

# Adicionar logs espec√≠ficos
kubectl logs <pod> -n <namespace> >> troubleshoot-report.txt

# Compartilhar relat√≥rio (remova senhas!)
```

## Recursos Externos

- [Kubernetes Troubleshooting](https://kubernetes.io/docs/tasks/debug/)
- [k3d Issues](https://github.com/k3d-io/k3d/issues)
- [ArgoCD Troubleshooting](https://argo-cd.readthedocs.io/en/stable/operator-manual/troubleshooting/)
- [Prometheus Troubleshooting](https://prometheus.io/docs/prometheus/latest/troubleshooting/)

---

**Dica**: Sempre comece com `./scripts/troubleshoot.sh` para diagn√≥stico autom√°tico!
