# üö® Troubleshooting Guide - Nexo CloudLab

Guia de solu√ß√£o de problemas comuns no CloudLab.

## Script Autom√°tico

```bash
# Rodar diagn√≥stico completo
./scripts/troubleshoot.sh

# Ou via Make
make troubleshoot
```

## Problemas Comuns

### 1. Cluster n√£o inicia

#### Sintoma

```bash
k3d cluster create --config config/k3d-config.yaml
# Error: ...
```

#### Solu√ß√µes

**Docker n√£o est√° rodando**

```bash
# Verificar
docker info

# Solu√ß√£o
open -a Docker
# Aguardar Docker iniciar
```

**Porta j√° em uso**

```bash
# Ver o que est√° usando as portas
lsof -i :80
lsof -i :443

# Matar processo
kill -9 <PID>

# Ou usar portas diferentes em k3d-config.yaml
```

**SSD n√£o montado**

```bash
# Verificar
ls -la /Volumes/Backup

# Se n√£o existir, montar o disco ou criar diret√≥rio local
mkdir -p ~/nexo-cloudlab-storage
# Editar config/k3d-config.yaml para usar ~/nexo-cloudlab-storage
```

### 2. Pods em CrashLoopBackOff

#### Sintoma

```bash
kubectl get pods -A
# NAME              STATUS             RESTARTS
# my-pod-xxx        CrashLoopBackOff   5
```

#### Debug

```bash
# Ver logs atuais
kubectl logs <pod> -n <namespace>

# Ver logs do container anterior
kubectl logs <pod> -n <namespace> --previous

# Describe para ver eventos
kubectl describe pod <pod> -n <namespace>

# Ver eventos do namespace
kubectl get events -n <namespace> --sort-by='.lastTimestamp'
```

#### Causas Comuns

**Image Pull Error**

```bash
# Sintoma: ImagePullBackOff

# Verificar
kubectl describe pod <pod> -n <namespace> | grep -A 5 "Events:"

# Solu√ß√µes:
# 1. Verificar se imagem existe
docker pull <image>

# 2. Verificar imagePullSecrets
kubectl get deployment <name> -n <namespace> -o yaml | grep imagePullSecrets

# 3. Criar secret se necess√°rio
kubectl create secret docker-registry ghcr-secret \
  --docker-server=ghcr.io \
  --docker-username=<user> \
  --docker-password=<token> \
  -n <namespace>
```

**Falta de Recursos**

```bash
# Sintoma: Insufficient memory/cpu

# Ver recursos dispon√≠veis
kubectl describe node | grep -A 5 "Allocated resources"

# Solu√ß√µes:
# 1. Reduzir resources do pod
# 2. Aumentar recursos do Docker Desktop (Settings ‚Üí Resources)
# 3. Deletar pods n√£o usados
kubectl delete pod <pod> -n <namespace>
```

**ConfigMap/Secret n√£o existe**

```bash
# Sintoma: Error: couldn't find key X in ConfigMap

# Verificar
kubectl get configmap -n <namespace>
kubectl get secret -n <namespace>

# Criar se necess√°rio
kubectl create configmap <name> --from-literal=key=value -n <namespace>
kubectl create secret generic <name> --from-literal=key=value -n <namespace>
```

### 3. Ingress n√£o funciona

#### Sintoma

```bash
curl http://develop-be.nexo.local
# Connection refused / 404
```

#### Debug

```bash
# Verificar Ingress Controller
kubectl get pods -n ingress-nginx

# Ver logs
kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller

# Ver ingresses
kubectl get ingress -A

# Describe ingress
kubectl describe ingress <name> -n <namespace>
```

#### Solu√ß√µes

**Ingress Controller n√£o est√° rodando**

```bash
helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace
```

**DNS n√£o configurado**

```bash
# Verificar /etc/hosts
cat /etc/hosts | grep local.nexo.dev

# Adicionar se n√£o existir
echo "127.0.0.1 develop-be.nexo.local" | sudo tee -a /etc/hosts
```

**Service n√£o existe**

```bash
# Ver services
kubectl get svc -n <namespace>

# Se n√£o existir, verificar deployment
kubectl get deployment -n <namespace>
```

### 4. ArgoCD n√£o sincroniza

#### Sintoma

```bash
argocd app get myapp
# Status: OutOfSync
# Sync: Failed
```

#### Debug

```bash
# Ver detalhes do erro
argocd app get myapp

# Ver logs do sync
argocd app logs myapp

# Ver diff
argocd app diff myapp

# Ver eventos
kubectl get events -n argocd --sort-by='.lastTimestamp'
```

#### Solu√ß√µes

**Erro de sintaxe no YAML**

```bash
# Validar manifesto localmente
helm template ./chart --debug

# Ou
kubectl apply --dry-run=client -f manifest.yaml
```

**Repo n√£o acess√≠vel**

```bash
# Verificar repo
argocd repo list

# Adicionar credenciais se necess√°rio
argocd repo add https://github.com/user/repo \
  --username <user> \
  --password <token>
```

**Path n√£o existe**

```bash
# Verificar path no repo
git clone <repo>
ls -la <path>

# Corrigir Application
kubectl edit application myapp -n argocd
```

### 5. Prometheus sem m√©tricas

#### Sintoma

```
Grafana: No data
Prometheus: Target down
```

#### Debug

```bash
# Ver targets
kubectl port-forward -n monitoring svc/prometheus-operated 9090:9090
# Acessar: http://localhost:9090/targets

# Ver ServiceMonitors
kubectl get servicemonitor -n monitoring

# Ver logs do Prometheus
kubectl logs -n monitoring prometheus-kube-prometheus-stack-prometheus-0
```

#### Solu√ß√µes

**ServiceMonitor n√£o tem label correto**

```yaml
# ServiceMonitor precisa ter:
metadata:
  labels:
    release: kube-prometheus-stack
```

**Service n√£o exp√µe /metrics**

```bash
# Testar diretamente
kubectl port-forward -n <namespace> svc/<service> 8080:8080
curl http://localhost:8080/metrics
```

**Namespace n√£o est√° sendo monitorado**

```yaml
# Verificar namespaceSelector no ServiceMonitor
spec:
  namespaceSelector:
    matchNames:
      - <namespace>
```

### 7. Pods Pending

#### Sintoma

```bash
kubectl get pods
# NAME         STATUS    RESTARTS
# my-pod-xxx   Pending   0
```

#### Debug

```bash
kubectl describe pod <pod> -n <namespace>
# Ver se√ß√£o "Events:"
```

#### Causas

**Insufficient CPU/Memory**

```bash
# Ver recursos dispon√≠veis
kubectl top nodes

# Solu√ß√µes:
# 1. Deletar pods n√£o usados
# 2. Reduzir resources.requests
# 3. Aumentar recursos do cluster
```

**Volume n√£o pode ser montado**

```bash
# Ver PVC
kubectl get pvc -n <namespace>

# Se Pending, verificar StorageClass
kubectl get storageclass

# Ver events do PVC
kubectl describe pvc <pvc-name> -n <namespace>
```

**Node selector n√£o matched**

```bash
# Ver node labels
kubectl get nodes --show-labels

# Remover nodeSelector ou adicionar label ao node
kubectl label node <node> <key>=<value>
```

### 8. Out of Memory

#### Sintoma

```bash
kubectl get pods
# NAME         STATUS    RESTARTS
# my-pod-xxx   OOMKilled 5
```

#### Solu√ß√µes

```yaml
# Aumentar memory limit
resources:
  limits:
    memory: 1Gi # Era 512Mi
  requests:
    memory: 512Mi
```

```bash
# Ver uso de mem√≥ria
kubectl top pods -n <namespace>

# Ver hist√≥rico no Grafana
# Dashboard ‚Üí Kubernetes Pods ‚Üí Memory Usage
```

### 9. Network Policies bloqueando

#### Sintoma

```
Pods n√£o conseguem comunicar
Timeout ao chamar services
```

#### Debug

```bash
# Ver network policies
kubectl get networkpolicies -A

# Describe
kubectl describe networkpolicy <name> -n <namespace>

# Testar conectividade
kubectl run -it --rm debug --image=nicolaka/netshoot --restart=Never -- bash
# Dentro do pod:
curl http://service-name.namespace:port
```

#### Solu√ß√£o

```bash
# Deletar policy temporariamente
kubectl delete networkpolicy <name> -n <namespace>

# Ou corrigir policy para permitir tr√°fego
```

### 10. Certificate/TLS Issues

#### Sintoma

```
x509: certificate signed by unknown authority
```

#### Para ambiente local

A plataforma opera inteiramente em **HTTP** ‚Äî n√£o h√° HTTPS/TLS configurado em nenhum ambiente.
Se este erro aparecer, verifique se algum servi√ßo est√° tentando acessar endpoints HTTPS.

```yaml
# Garantir que ingress N√ÉO redireciona para HTTPS
ingress:
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
```

### 11. Keycloak / Auth Issues

#### Sintoma: "Web Crypto API is not available"

O frontend exibe erro no console:

```
Web Crypto API is not available
```

#### Causa

O `keycloak-js` foi configurado com `pkceMethod: "S256"`, que utiliza a Web Crypto API (`crypto.subtle`). Essa API s√≥ est√° dispon√≠vel em **secure contexts** (HTTPS ou localhost). Como o CloudLab usa HTTP com dom√≠nios `.nexo.local`, o browser bloqueia o acesso.

#### Solu√ß√£o

Remover `pkceMethod: "S256"` do `keycloak.init()` em `auth-provider.tsx`:

```typescript
// ‚ùå N√£o funciona em HTTP
keycloak.init({ onLoad: "check-sso", pkceMethod: "S256" });

// ‚úÖ Funciona em HTTP
keycloak.init({ onLoad: "check-sso" });
```

> **Nota:** Toda a plataforma opera em HTTP ‚Äî PKCE S256 n√£o √© utilizado em nenhum ambiente.

#### Sintoma: Keycloak "HTTPS required"

O Keycloak exibe "We are sorry... HTTPS required" ao acessar o admin console.

#### Causa

O realm no banco de dados foi inicializado com `sslRequired=ALL` ou `sslRequired=EXTERNAL` de uma execu√ß√£o anterior que n√£o usava `start-dev`.

#### Solu√ß√£o

1. Parar os containers: `docker compose down`
2. Limpar os dados do PostgreSQL no SSD: `sudo rm -rf /Volumes/Backup/nexo-cloudlab/data/postgres`
3. Recriar o diret√≥rio: `mkdir -p /Volumes/Backup/nexo-cloudlab/data/postgres`
4. Subir novamente: `docker compose up -d`

O Keycloak em modo `start-dev` inicializa os realms com `sslRequired=NONE` automaticamente.

> **Importante:** Isso apaga TODOS os dados do Keycloak e PostgreSQL. Exporte configs antes se necess√°rio.

#### Sintoma: Keycloak 503 Service Temporarily Unavailable

O Keycloak retorna 503 durante o startup. Isso √© **normal** ‚Äî o Keycloak leva 2-4 minutos para inicializar completamente.

#### Solu√ß√£o

```bash
# Verificar se o pod est√° rodando
kubectl get pods -n nexo-develop -l app=nexo-auth

# Aguardar readiness probe (180-240s initial delay)
kubectl wait --for=condition=ready pod -l app=nexo-auth -n nexo-develop --timeout=300s

# Testar endpoint
curl -s -o /dev/null -w "%{http_code}" http://develop-auth.nexo.local/realms/master
```

#### Sintoma: Keycloak em loop de restart (QA/Staging)

Se o Keycloak em QA/staging fica em CrashLoopBackOff, verifique se est√° usando `start-dev` e n√£o `start`:

```yaml
# values-qa.yaml / values-staging.yaml
keycloak:
  args: "start-dev"  # ‚úÖ Dev mode (mais r√°pido, sem build otimizado)
  # args: "start"    # ‚ùå Production mode (requer configura√ß√µes extras)
```

### 12. PostgreSQL n√£o inicia no SSD Externo (macOS)

#### Sintoma

```
find: /var/lib/postgresql/data/._.metadata_never_index: Operation not permitted
dependency failed to start: container nexo-postgres-dev is unhealthy
```

#### Causa

macOS cria arquivos `._*` (AppleDouble metadata) em volumes externos (SSD). O PostgreSQL no container Alpine n√£o consegue ler esses arquivos, causando falha no entrypoint.

#### Solu√ß√£o

O `docker-compose.yml` usa `PGDATA` apontando para um subdiret√≥rio `pgdata/` dentro do volume:

```yaml
environment:
  PGDATA: /var/lib/postgresql/data/pgdata  # Subdiret√≥rio limpo
volumes:
  - /Volumes/Backup/nexo-cloudlab/data/postgres:/var/lib/postgresql/data
```

Se o problema persistir, limpe os dados e reinicie:

```bash
docker compose down
sudo rm -rf /Volumes/Backup/nexo-cloudlab/data/postgres
mkdir -p /Volumes/Backup/nexo-cloudlab/data/postgres
docker compose up -d
```

---

## Comandos de Emerg√™ncia

### Restart Everything

```bash
# Restart todos pods de um namespace
kubectl delete pods --all -n <namespace>

# Restart deployment
kubectl rollout restart deployment <name> -n <namespace>

# Restart daemonset
kubectl rollout restart daemonset <name> -n <namespace>
```

### Force Delete

```bash
# Deletar pod travado
kubectl delete pod <pod> -n <namespace> --force --grace-period=0

# Remover finalizers
kubectl patch pod <pod> -n <namespace> -p '{"metadata":{"finalizers":[]}}' --type=merge
```

### Clean Cluster

```bash
# Deletar pods failed/completed
kubectl delete pods --field-selector=status.phase=Failed -A
kubectl delete pods --field-selector=status.phase=Succeeded -A

# Limpar Docker
docker system prune -a
```

### Nuclear Option

```bash
# Deletar tudo e recome√ßar
make clean
make install
```

## Logs Importantes

### Cluster

```bash
# Kubernetes events
kubectl get events -A --sort-by='.lastTimestamp' | tail -n 50

# Node logs (via Docker)
docker logs k3d-nexo-local-server-0
docker logs k3d-nexo-local-agent-0
```

### Componentes

```bash
# ArgoCD
kubectl logs -n argocd -l app.kubernetes.io/name=argocd-server

# Prometheus
kubectl logs -n monitoring prometheus-kube-prometheus-stack-prometheus-0

# Grafana
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana

# Elasticsearch
kubectl logs -n logging elasticsearch-master-0

# Ingress
kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller
```

## üóëÔ∏è Quando Reinstalar do Zero

√Äs vezes, a solu√ß√£o mais r√°pida √© destruir tudo e reinstalar. Use o comando **destroy** quando:

- Muitas coisas quebradas ao mesmo tempo
- Configura√ß√µes corrompidas
- Problemas persistentes sem causa clara
- Quer come√ßar limpo ap√≥s testes

### Op√ß√µes de Limpeza

#### 1. Delete (apenas cluster)

Remove apenas o cluster, mant√©m volumes:

```bash
make delete
# ou
k3d cluster delete nexo-local
```

**Use quando:** Quer recriar o cluster mas manter dados (Prometheus, ES, etc)

#### 2. Clean (cluster + volumes)

Remove cluster e limpa volumes do SSD:

```bash
make clean
```

**Use quando:** Quer limpar dados mas manter /etc/hosts

#### 3. Destroy (TUDO)

Remove TUDO de forma interativa com confirma√ß√£o:

```bash
make destroy
# ou
cd local && ./destroy.sh
```

**Remove:**

- ‚úÖ Todos os Helm releases (ArgoCD, Prometheus, ES, etc)
- ‚úÖ Todos os namespaces
- ‚úÖ Cluster k3d completo
- ‚úÖ Volumes persistentes (com confirma√ß√£o)
- ‚úÖ Entradas no /etc/hosts (com confirma√ß√£o)

**Use quando:**

- Problemas graves sem solu√ß√£o clara
- Quer come√ßar 100% do zero
- Vai recriar o ambiente completo

### Processo Completo de Reinstala√ß√£o

```bash
# 1. Destroy completo
cd local
make destroy
# Confirme as op√ß√µes interativas (volumes e /etc/hosts)

# 2. Reinstalar
make setup

# 3. Verificar
make status
make urls
```

### Backup Antes de Destroy

**SEMPRE fa√ßa backup antes de destruir:**

```bash
# Backup completo
make backup

# Backup manual de recursos importantes
kubectl get all -A -o yaml > backup-all-resources.yaml
kubectl get configmaps -A -o yaml > backup-configmaps.yaml
kubectl get secrets -A -o yaml > backup-secrets.yaml
```

Os backups ficam em: `/Volumes/Backup/nexo-cloudlab/backups/`

## Quando Pedir Ajuda

Se nada funcionar, colete informa√ß√µes e pe√ßa ajuda:

```bash
# Gerar relat√≥rio completo
./scripts/troubleshoot.sh > troubleshoot-report.txt

# Adicionar logs espec√≠ficos
kubectl logs <pod> -n <namespace> >> troubleshoot-report.txt

# Compartilhar relat√≥rio (remova senhas!)
```

## Recursos Externos

- [Kubernetes Troubleshooting](https://kubernetes.io/docs/tasks/debug/)
- [k3d Issues](https://github.com/k3d-io/k3d/issues)
- [ArgoCD Troubleshooting](https://argo-cd.readthedocs.io/en/stable/operator-manual/troubleshooting/)
- [Prometheus Troubleshooting](https://prometheus.io/docs/prometheus/latest/troubleshooting/)

---

**Dica**: Sempre comece com `./scripts/troubleshoot.sh` para diagn√≥stico autom√°tico!
